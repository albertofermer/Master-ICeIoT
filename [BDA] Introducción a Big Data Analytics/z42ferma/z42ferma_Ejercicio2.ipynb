{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ylJzIeQc84iq",
        "4ckzowVT-i_N",
        "uRT6k2kf_LQd",
        "vryRCvMC6oWZ",
        "1OEEyk656oyJ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introducción**\n",
        "\n",
        "\n",
        "*   Queremos analizar el comportamiento de nuestra aplicación\n",
        "web. Para ello, el servidor proporciona un fichero log, que una\n",
        "vez convertido a csv, ofrece las siguientes columnas:\n",
        "  * Dirección IP del cliente que genera la solicitud.\n",
        "  * Fecha y hora de la solicitud\n",
        "  * Recurso solicitado, que puede ser la solicitud de una página (php)\n",
        "o recursos estáticos como imágenes\n",
        "  * Estado de respuesta HTTP, de la forma “HTTP1.1,<código>”\n",
        "donde <código> es un dígito que implica:\n",
        "  * Respuestas satisfactorias (200–299)\n",
        "  * Redirecciones (300–399)\n",
        "  * Errores de los clientes (400–499)\n",
        "* 3 meses de funcionamiento del servidor genera +1MB de\n",
        "fichero texto, y se espera que se incremente exponencialmente\n",
        "el volumen *conforme* aumente el tráfico del sitio y este crezca.\n",
        "\n",
        "* Diseñe el trabajo/s MapReduce, así como las tareas y procedimientos implicados (arquitectura y\n",
        "pseudocódigo) para realizar los siguientes análisis sobre el servidor de nuestra aplicación:\n",
        "\n",
        "  2. Para aquellas solicitudes a páginas php respondidas exitosamente, queremos saber cuántos\n",
        "accesos únicos (distintos clientes) ha tenido cada página.\n",
        "\n",
        "  4. Queremos conocer la frecuencia de acceso de cada cliente a recursos de nuestro servidor.\n",
        "  5. Con el fin de detectar posibles ataques o errores, queremos conocer el número de respuestas no\n",
        "correctas que se han devuelto a los clientes que han recibido al menos un error. [Opcional]\n",
        "* Considere cada uno de los puntos anteriores como un ejercicio MapReduce distinto asociado al mismo\n",
        "dominio de problema.\n",
        "* Entregue las respuestas como parte de su informe de prácticas al profesor en un documento PDF.\n",
        "* Estos ejercicios se pueden hacer en parejas (2) de estudiantes, siempre que se trate de pair-programming.\n",
        "* Aproveche cuando sea posible las ventajas que ofrece la programación funcional y la comprensión de listas, así como\n",
        "las estructuras que ofrece Spark y librerías asociadas (PySpark).\n",
        "* Las respuestas de código deben entregarse como un notebook (ipynb) ejecutable en Google Colab, para garantizar\n",
        "la uniformidad en el entorno de desarrollo.\n",
        "* Puede entregar bien los notebooks junto al informe de prácticas (zip) o un enlace a su cuaderno Google Colab. En\n",
        "cualquier caso, llame a su cuaderno de la siguiente forma: <login(s)>_problema<letra>\n",
        "* Explique suficientemente cada paso que realiza: la revisión de código no sólo se fundamenta en ejecutarlo, también\n",
        "en entenderlo sin esfuerzo (legibilidad y comprensibilidad) – ¡Programe siempre para un tercero!"
      ],
      "metadata": {
        "id": "K9MwsPBe1n3c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalación del entorno**"
      ],
      "metadata": {
        "id": "9NsCQThF2r0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalación de Hadoop\n",
        "\n",
        "Instalamos la versión de Hadoop/Spark 3.2.4\n",
        "Se recomienda visitar el sitio de Apache Spark para descargar esta versión:\n",
        "\n",
        "https://spark.apache.org/downloads.html\n",
        "\n",
        "Se configuran posteriormente las variables de entorno `JAVA_HOME` y `SPARK_HOME`"
      ],
      "metadata": {
        "id": "Uhc57NWN51to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.4-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "gknxsaLR2rUP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.apache.org/dist/spark/spark-3.2.4/spark-3.2.4-bin-hadoop3.2.tgz\n",
        "!tar -xf spark-3.2.4-bin-hadoop3.2.tgz\n",
        "!rm spark-3.2.4-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAFtvd3M2y32",
        "outputId": "cff07e44-fa03-4367-dd25-7ad78ab01b6a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-19 18:52:39--  https://archive.apache.org/dist/spark/spark-3.2.4/spark-3.2.4-bin-hadoop3.2.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 301183180 (287M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.2.4-bin-hadoop3.2.tgz’\n",
            "\n",
            "spark-3.2.4-bin-had 100%[===================>] 287.23M  23.3MB/s    in 13s     \n",
            "\n",
            "2025-01-19 18:52:53 (21.8 MB/s) - ‘spark-3.2.4-bin-hadoop3.2.tgz’ saved [301183180/301183180]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalación de Spark"
      ],
      "metadata": {
        "id": "ouVI4Y1u2_52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk_qjQnV3C-l",
        "outputId": "23709ebe-ecbf-4261-9685-22efd4e96b88"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.11/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Descarga del dataset**"
      ],
      "metadata": {
        "id": "v2pGaFay4Gk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://www.kaggle.com/api/v1/datasets/download/shawon10/web-log-dataset\"\n",
        "!unzip web-log-dataset -d data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sca7WtJNy4zv",
        "outputId": "9b845cd6-c288-4268-af23-45c6c7b859d2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-19 18:53:00--  https://www.kaggle.com/api/v1/datasets/download/shawon10/web-log-dataset\n",
            "Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n",
            "Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com:443/kaggle-data-sets/14835/848738/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250119%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250119T185300Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=2db04c9224708ec11e9a70e15fc73dbfac8327fbd56c343d3c760106fe67e00d383b98bbd4b581149b32baff5ab992ef9a18206785b17304eb19c1a61bced2de5df0fba5a7a03f107082eaf466bce56f3a6123d1db8128fad4fbef794cd328ab676c8ed07b374c9b6f1dd2ef147921e05a57158d96d244c90d5d25ad1e9e49dbae9b997f1c070f37d7d5c9890507f3f01e99057697755404c65cb36f04aba1e3aa86d6a91287b2e8fc51e6b4706c1062d6b7f2ae007adc1dda861883250dc1d18efdaf4553cfdda01315aeab04c4fc8327fee93802cb1c7c74b71860fdc98f96a9dbf046ecf8649f58bb98abb34ae2b7c2d63dd6890ddb7243e982988333d332 [following]\n",
            "--2025-01-19 18:53:00--  https://storage.googleapis.com/kaggle-data-sets/14835/848738/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250119%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250119T185300Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=2db04c9224708ec11e9a70e15fc73dbfac8327fbd56c343d3c760106fe67e00d383b98bbd4b581149b32baff5ab992ef9a18206785b17304eb19c1a61bced2de5df0fba5a7a03f107082eaf466bce56f3a6123d1db8128fad4fbef794cd328ab676c8ed07b374c9b6f1dd2ef147921e05a57158d96d244c90d5d25ad1e9e49dbae9b997f1c070f37d7d5c9890507f3f01e99057697755404c65cb36f04aba1e3aa86d6a91287b2e8fc51e6b4706c1062d6b7f2ae007adc1dda861883250dc1d18efdaf4553cfdda01315aeab04c4fc8327fee93802cb1c7c74b71860fdc98f96a9dbf046ecf8649f58bb98abb34ae2b7c2d63dd6890ddb7243e982988333d332\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.194.207, 142.250.152.207, 172.217.214.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.194.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82459 (81K) [application/zip]\n",
            "Saving to: ‘web-log-dataset.1’\n",
            "\n",
            "web-log-dataset.1   100%[===================>]  80.53K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-01-19 18:53:00 (62.4 MB/s) - ‘web-log-dataset.1’ saved [82459/82459]\n",
            "\n",
            "Archive:  web-log-dataset\n",
            "replace data/weblog.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data/weblog.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializamos SparkSession"
      ],
      "metadata": {
        "id": "F_EFN6wcCdVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        ".master(\"local[*]\") \\\n",
        ".appName(\"Spark_Dataframes\") \\\n",
        ".getOrCreate()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "J0rKQFiHB_2Y",
        "outputId": "301e7676-1088-4dc1-a361-2914dc9cada8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ccafd98fb50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://541a99d36206:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark_Dataframes</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = spark.read.csv('data/weblog.csv', header=True)\n",
        "ds.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4pQW6bC4O3Y",
        "outputId": "52b70e8e-74ad-4934-f210-82ac75002c91"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------------------+---------------------------------------------+-----+\n",
            "|IP        |Time                 |URL                                          |Staus|\n",
            "+----------+---------------------+---------------------------------------------+-----+\n",
            "|10.128.2.1|[29/Nov/2017:06:58:55|GET /login.php HTTP/1.1                      |200  |\n",
            "|10.128.2.1|[29/Nov/2017:06:59:02|POST /process.php HTTP/1.1                   |302  |\n",
            "|10.128.2.1|[29/Nov/2017:06:59:03|GET /home.php HTTP/1.1                       |200  |\n",
            "|10.131.2.1|[29/Nov/2017:06:59:04|GET /js/vendor/moment.min.js HTTP/1.1        |200  |\n",
            "|10.130.2.1|[29/Nov/2017:06:59:06|GET /bootstrap-3.3.7/js/bootstrap.js HTTP/1.1|200  |\n",
            "+----------+---------------------+---------------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 2**\n",
        "\n",
        "Para aquellas solicitudes a páginas php respondidas exitosamente, queremos saber cuántos accesos únicos (distintos clientes) ha tenido cada página.\n"
      ],
      "metadata": {
        "id": "4ckzowVT-i_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, trim, countDistinct\n",
        "\n",
        "# Inicializamos la SparkSession\n",
        "spark = SparkSession.builder.appName(\"Exercise_B\").getOrCreate()\n",
        "\n",
        "# Cargamos el dataset\n",
        "logs = spark.read.csv(\"data/weblog.csv\", header=True)\n",
        "\n",
        "# Obtenemos las columnas Status (Staus) y URL\n",
        "logs = logs.withColumn(\"Staus\", trim(col(\"Staus\")))\n",
        "logs = logs.withColumn(\"URL\", trim(col(\"URL\")))\n",
        "\n",
        "# Filtramos los registros de modo que nos devuelva las solicitudes que tengan un 20x en el Status y que\n",
        "# acaben en .php\n",
        "filtered_logs = logs.filter(col(\"Staus\").rlike(\"^20[0-9]$\")).filter(col(\"URL\").contains(\".php\"))\n",
        "\n",
        "# Agrupamos por URL y contamos los accesos unicos mediante la IP del usuario\n",
        "result = filtered_logs.groupBy(\"URL\").agg(countDistinct(\"IP\").alias(\"Accesos_Unicos\"))\n",
        "result.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed33fe0-5f3b-4668-ee05-c78c84c9b807",
        "id": "6hwbP-xM-W3a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------+--------------+\n",
            "|URL                                                 |Accesos_Unicos|\n",
            "+----------------------------------------------------+--------------+\n",
            "|GET /compiler.php HTTP/1.1                          |5             |\n",
            "|GET /allsubmission.php?page=5 HTTP/1.1              |2             |\n",
            "|POST /pcompile.php HTTP/1.1                         |5             |\n",
            "|GET /contestsubmission.php?id=4&show=shawon HTTP/1.1|2             |\n",
            "|GET /editcontestproblem.php?id=41 HTTP/1.1          |1             |\n",
            "|POST /contestsubmission.php HTTP/1.1                |5             |\n",
            "|GET /showcode.php?id=308&nm=ham05 HTTP/1.1          |1             |\n",
            "|GET /submit.php?id=68 HTTP/1.1                      |1             |\n",
            "|GET /profile.php?user=mahadi HTTP/1.1               |1             |\n",
            "|GET /home.php HTTP/1.1                              |5             |\n",
            "|GET /sign.php?value=fail HTTP/1.1                   |4             |\n",
            "|GET /standings.php?id=13 HTTP/1.1                   |3             |\n",
            "|GET /allsubmission.php?name=mahadi HTTP/1.1         |1             |\n",
            "|GET /edit.php?name=m.r.saurov HTTP/1.1              |1             |\n",
            "|GET /profile.php?user=mdshs.shanto HTTP/1.1         |1             |\n",
            "|GET /contestsubmission.php?id=13&page=4 HTTP/1.1    |1             |\n",
            "|GET /allsubmission.php?page=4 HTTP/1.1              |2             |\n",
            "|GET /profile.php?user=mkarzymat HTTP/1.1            |1             |\n",
            "|GET /details.php?id=38 HTTP/1.1                     |1             |\n",
            "|GET /showcode.php?id=296&nm=bruce HTTP/1.1          |1             |\n",
            "+----------------------------------------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}